{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purely for google colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd \"/content/drive/MyDrive/fypj_final_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pipelineprofiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PipelineProfiler\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one model\n",
    "def load_pickle_data(pickle_path):\n",
    "    return pickle.load(open(pickle_path,'rb'))\n",
    "\n",
    "menu_str=\"\"\" Load what model? \\n\n",
    "\"\"\"\n",
    "index_count = 0\n",
    "for k in os.listdir(\"./saved_models\"):\n",
    "    menu_str+=f\"{index_count}. {k} \\n\"\n",
    "    index_count+=1\n",
    "print(menu_str)\n",
    "while True:\n",
    "    try:\n",
    "        selected_model_index = int(input(\"Select a model to load (enter integer index): \").strip())\n",
    "        break\n",
    "    except:\n",
    "        print(\"Please select a valid model index.\")\n",
    "model_name = os.listdir(\"./saved_models\")[selected_model_index]\n",
    "print(f\"Selected model to load: index = {selected_model_index}, model_name = {model_name}\")\n",
    "name_of_model = model_name\n",
    "with open(f\"./saved_models/{model_name}/{model_name}.pkl\",\"rb\") as f:\n",
    "    automl_classification = pickle.load(f)\n",
    "    print(\"Selected model has been loaded successfully!\")\n",
    "\n",
    "# load data\n",
    "DATADIR = f\"./saved_models/{model_name}/data/\"\n",
    "X_test = load_pickle_data(DATADIR+\"X_test.pkl\")\n",
    "X_train = load_pickle_data(DATADIR+\"X_train.pkl\")\n",
    "y_test = load_pickle_data(DATADIR+\"y_test.pkl\")\n",
    "y_train = load_pickle_data(DATADIR+\"y_train.pkl\")\n",
    "predictions = automl_classification.predict(X_test)\n",
    "accu_ = sklearn.metrics.accuracy_score(y_test,predictions)\n",
    "f1_ = sklearn.metrics.f1_score(y_test,predictions,average=\"weighted\",pos_label=\"Present\")\n",
    "print(\"Training and testing data has been loaded successfully!\\n\")\n",
    "print(f\"Resulting accuracy : {accu_} , Resulting f1 : {f1_}\")\n",
    "\n",
    "\n",
    "\n",
    "# EVALUATE PERFORMANCE\n",
    "# ONLY USE ON DATA WITHOUT UNKNOWN CLASS \n",
    "try:\n",
    "    print(f\"Ensemble size = {automl_classification.ensemble_size}\")\n",
    "    data = PipelineProfiler.import_autosklearn(automl_classification)\n",
    "    PipelineProfiler.plot_pipeline_matrix(data)\n",
    "\n",
    "    # evaluate performance \n",
    "    predictions_proba = automl_classification.predict_proba(X_test)\n",
    "    predictions = automl_classification.predict(X_test)\n",
    "    # training performance\n",
    "    predictions_training = automl_classification.predict(X_train)\n",
    "    # probability dataframe\n",
    "    proba_df = pd.DataFrame(data=predictions_proba,columns=[\"Absent Probability\",\"Present Probability\"])\n",
    "    proba_df[\"Predicted Label\"] = predictions\n",
    "    proba_df[\"Actual Label\"] = y_test\n",
    "    # accuracy and f1 score\n",
    "    print(\"Ensemble Accuracy on testing set: \",sklearn.metrics.accuracy_score(y_test,predictions))\n",
    "    print(\"Ensemble f1_score on testing set: \",sklearn.metrics.f1_score(y_test,predictions,average=\"weighted\",pos_label=\"Present\"),\"\\n\")\n",
    "\n",
    "    print(\"Ensemble Accuracy on training set: \",sklearn.metrics.accuracy_score(y_train,predictions_training))\n",
    "    print(\"Ensemble f1_score on training set: \",sklearn.metrics.f1_score(y_train,predictions_training,average=\"weighted\",pos_label=\"Present\"),\"\\n\")\n",
    "\n",
    "    # precision and recall\n",
    "    print(\"Ensemble Precision on testing set:\",sklearn.metrics.precision_score(y_test,predictions,pos_label=\"Present\"))\n",
    "    print(\"Ensemble Recall on testing set:\",sklearn.metrics.recall_score(y_test,predictions,pos_label=\"Present\"),\"\\n\")\n",
    "\n",
    "    print(\"Ensemble Precision on training set:\",sklearn.metrics.recall_score(y_train,predictions_training,pos_label=\"Present\"))\n",
    "    print(\"Ensemble Recall on training set:\",sklearn.metrics.recall_score(y_train,predictions_training,pos_label=\"Present\"),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(proba_df)\n",
    "    fig,ax = plt.subplots(ncols=2,nrows=2,figsize=(15,10))\n",
    "    sklearn.metrics.plot_confusion_matrix(X=X_test,y_true=y_test,estimator=automl_classification,ax=ax[0,0])\n",
    "    ax[0,0].title.set_text(\"Confusion matrix of model on testing set\")\n",
    "    sklearn.metrics.plot_confusion_matrix(X=X_train,y_true=y_train,estimator=automl_classification,ax=ax[0,1])\n",
    "    ax[0,1].title.set_text(\"Confusion matrix of model on training set\")\n",
    "\n",
    "    # show roc curve on both training and testing set\n",
    "    sklearn.metrics.plot_roc_curve(automl_classification,X_test,y_test,ax=ax[1,0])\n",
    "    ax[1,0].title.set_text(\"ROC Curve of model on testing set\")\n",
    "    sklearn.metrics.plot_roc_curve(automl_classification,X_train,y_train,ax=ax[1,1])\n",
    "    ax[1,1].title.set_text(\"ROC Curve of model on training set\")\n",
    "except:\n",
    "    print(\"Data contains unknown class. Cannot display ROC Curve\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load , evaluate and produce dataframe\n",
    "evaluate_model_df = pd.DataFrame(data=[],columns=[\"model_name\",\"accuracy\",\"f1\"])\n",
    "for k in os.listdir(\"./saved_models\"):\n",
    "    model_name = k\n",
    "    with open(f\"./saved_models/{model_name}/{model_name}.pkl\",\"rb\") as f:\n",
    "        automl_classification = pickle.load(f)\n",
    "    # load data\n",
    "    DATADIR = f\"./saved_models/{model_name}/data/\"\n",
    "    X_test = load_pickle_data(DATADIR+\"X_test.pkl\")\n",
    "    X_train = load_pickle_data(DATADIR+\"X_train.pkl\")\n",
    "    y_test = load_pickle_data(DATADIR+\"y_test.pkl\")\n",
    "    y_train = load_pickle_data(DATADIR+\"y_train.pkl\")\n",
    "\n",
    "    predictions = automl_classification.predict(X_test)\n",
    "    resulting_f1=sklearn.metrics.f1_score(y_test,predictions,average=\"weighted\",pos_label=\"Present\")\n",
    "    resulting_acc=sklearn.metrics.accuracy_score(y_test,predictions)\n",
    "    evaluate_model_df.loc[evaluate_model_df.shape[0]] = [\n",
    "        k,\n",
    "        resulting_acc,\n",
    "        resulting_f1\n",
    "    ]\n",
    "    print(f\"Evaluation of model {model_name} successful.\")\n",
    "\n",
    "print(evaluate_model_df)\n",
    "evaluate_model_df.to_excel(\"./f1_score_accuracy_model_results.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b43543f65750abaf68843f05bc2f17d6c89e154a5075b0a110863194543eb828"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ubuntu_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
