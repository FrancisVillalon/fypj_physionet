{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze \"requirements.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa \n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from audiomentations import *\n",
    "import warnings\n",
    "import scipy.signal\n",
    "from pydub import AudioSegment\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augments\n",
    "augment = Compose([\n",
    "    Reverse(p=0.8),\n",
    "    PolarityInversion(p=1)\n",
    "])\n",
    "\n",
    "augment_spec = SpecCompose([\n",
    "    SpecFrequencyMask(p=1)\n",
    "])\n",
    "\n",
    "def augment_signal(S,sr,outputpath):\n",
    "    augmented_signal = augment(S,sr)\n",
    "    sf.write(outputpath,augmented_signal,sr)\n",
    "\n",
    "\n",
    "# for balancing\n",
    "def grab_id(amt,val_srs):\n",
    "    temp_idx=[]\n",
    "    temp_count=0\n",
    "    for i,k in val_srs.iteritems():\n",
    "        if temp_count >= amt:\n",
    "            break\n",
    "        else:\n",
    "            temp_count+=k\n",
    "            temp_idx.append(i)\n",
    "    return temp_idx\n",
    "\n",
    "# feature extraction functions\n",
    "def mfccs_features_extract(S,sr):\n",
    "    mfccs_features = librosa.feature.mfcc(y=S, sr=sr, n_mfcc= 40,n_fft=len(S))\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis= 0)\n",
    "    return mfccs_scaled_features,mfccs_features\n",
    "\n",
    "def segment_audio(t1,t2,fn):\n",
    "    t1 = t1 * 1000\n",
    "    t2 = t2 * 1000\n",
    "    segemented_audio = AudioSegment.from_wav(fn)\n",
    "    segemented_audio = segemented_audio[t1:t2]\n",
    "    return segemented_audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_path = \"./1.0.1/\"\n",
    "augment_path = \"./1.0.1/training_data_balanced/\"\n",
    "records = data_path+ \"RECORDS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution by patient id\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Absent     0.737792\n",
       "Present    0.190021\n",
       "Unknown    0.072187\n",
       "Name: Murmur, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics = pd.read_csv(data_path+\"training_data.csv\")\n",
    "print(\"Class distribution by patient id\")\n",
    "demographics[\"Murmur\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution by audio recordings\n",
      " Absent     0.755928\n",
      "Present    0.194752\n",
      "Unknown    0.049320\n",
      "Name: Murmur, dtype: float64\n",
      "\n",
      "Training set class distribution (Pre-Augment)\n",
      " Absent     2089\n",
      "Present     314\n",
      "Name: Murmur, dtype: int64\n",
      "\n",
      "Augmenting present class audio data\n",
      "\n",
      "                       filenames patient_id   Murmur\n",
      "16    training_data/14241_AV.wav      14241  Present\n",
      "17    training_data/14241_MV.wav      14241  Present\n",
      "18    training_data/14241_PV.wav      14241  Present\n",
      "19    training_data/14241_TV.wav      14241  Present\n",
      "20    training_data/14998_AV.wav      14998   Absent\n",
      "...                          ...        ...      ...\n",
      "3158  training_data/85345_AV.wav      85345   Absent\n",
      "3159  training_data/85345_PV.wav      85345   Absent\n",
      "3160  training_data/85349_AV.wav      85349   Absent\n",
      "3161  training_data/85349_PV.wav      85349   Absent\n",
      "3162  training_data/85349_TV.wav      85349   Absent\n",
      "\n",
      "[2403 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# read all audio recordings and augment\n",
    "with open(records,'r') as r:\n",
    "    filenames = r.readlines()\n",
    "\n",
    "    # dataframe containing audio recording path with corresponding patient_id\n",
    "    file_df = pd.DataFrame(filenames,columns=[\"filenames\"])\n",
    "    file_df[\"filenames\"] = file_df[\"filenames\"].str.strip() + '.wav'\n",
    "    file_df[\"patient_id\"] = file_df[\"filenames\"].str.split(\"/\").str[1]\n",
    "    file_df[\"patient_id\"] = file_df[\"patient_id\"].str.split(\"_\").str[0].astype(str)\n",
    "    # merge with demographics to enrich dataframe\n",
    "    demographics[\"Patient ID\"] = demographics[\"Patient ID\"].astype(str)\n",
    "    file_df = file_df.merge(\n",
    "        demographics[[\"Murmur\",\"Patient ID\"]],\n",
    "        how='left',\n",
    "        left_on='patient_id',\n",
    "        right_on='Patient ID'\n",
    "    )\n",
    "    file_df.pop(\"Patient ID\")\n",
    "# class distribution by audio recordings\n",
    "print(\"Class distribution by audio recordings\"+ \"\\n\" ,file_df[\"Murmur\"].value_counts(normalize=True)) #Heavily biased to absent class\n",
    "\n",
    "# grabbing only present and absent class\n",
    "file_df_present = file_df.loc[file_df[\"Murmur\"]==\"Present\"]\n",
    "file_df_absent = file_df.loc[file_df[\"Murmur\"]==\"Absent\"]\n",
    "\n",
    "# creating test df\n",
    "test_present_ids = grab_id(300,file_df_present[\"patient_id\"].value_counts())\n",
    "test_absent_ids = grab_id(300,file_df_absent[\"patient_id\"].value_counts())\n",
    "test_ids = test_absent_ids+test_present_ids\n",
    "test_df = file_df.loc[file_df[\"patient_id\"].isin(test_ids)]\n",
    "\n",
    "# create train df\n",
    "train_df = file_df.loc[~(file_df[\"patient_id\"].isin(test_ids)) & (file_df[\"Murmur\"] != \"Unknown\")]\n",
    "print(\"\\nTraining set class distribution (Pre-Augment)\\n\",train_df[\"Murmur\"].value_counts())\n",
    "print(\"\\nAugmenting present class audio data\\n\")\n",
    "\n",
    "print(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2267/896978725.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"data\"] = np.array(None)\n",
      "100%|██████████| 2403/2403 [08:29<00:00,  4.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               filenames patient_id   Murmur  \\\n",
      "0      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "1      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "2      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "3      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "4      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "...                                                  ...        ...      ...   \n",
      "49892  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49893  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49894  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49895  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49896  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "\n",
      "       data  \n",
      "0      None  \n",
      "1      None  \n",
      "2      None  \n",
      "3      None  \n",
      "4      None  \n",
      "...     ...  \n",
      "49892  None  \n",
      "49893  None  \n",
      "49894  None  \n",
      "49895  None  \n",
      "49896  None  \n",
      "\n",
      "[49897 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "train_df[\"data\"] = np.array(None)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "SEGMENTDIR = augment_path+\"training_data/segmented_data\"\n",
    "new_train_df = pd.DataFrame(data=[],columns=[\"filenames\",\"patient_id\",\"Murmur\",\"data\"])\n",
    "for i,k in tqdm(train_df.copy().iterrows(),total=train_df.copy().shape[0]):\n",
    "    segments_ = k[\"filenames\"].split(\"/\")[1]\n",
    "    tsv_name = segments_.replace(\".wav\",\".tsv\")\n",
    "    tsv_df = pd.read_csv(f\"{augment_path}/training_data/{tsv_name}\",sep='\\t',header=None)\n",
    "    tsv_df_1 = tsv_df.loc[tsv_df[2] == 1][0].values.tolist()\n",
    "    tsv_df_4 = tsv_df.loc[tsv_df[2] == 4][1].values.tolist()\n",
    "    \n",
    "    if len(tsv_df_1) < len(tsv_df_4):\n",
    "        for n in range(len(tsv_df_1)):\n",
    "            segemented_audio_name = segments_.split(\".\")[0]+f\"_s{n}.wav\"\n",
    "            export_audio = segment_audio(tsv_df_1[n],tsv_df_4[n],augment_path+k[\"filenames\"])\n",
    "            export_audio.export(SEGMENTDIR+f\"/{segemented_audio_name}\",format=\"wav\")\n",
    "            full_export_path = SEGMENTDIR+f\"/{segemented_audio_name}\"\n",
    "            new_train_df.loc[new_train_df.shape[0]] = [\n",
    "                full_export_path,k[\"patient_id\"],k[\"Murmur\"],None\n",
    "            ]\n",
    "    else:\n",
    "        for n in range(len(tsv_df_4)):\n",
    "            segemented_audio_name = segments_.split(\".\")[0]+f\"_s{n}.wav\"\n",
    "            export_audio = segment_audio(tsv_df_1[n],tsv_df_4[n],augment_path+k[\"filenames\"])\n",
    "            export_audio.export(SEGMENTDIR+f\"/{segemented_audio_name}\",format=\"wav\")\n",
    "            full_export_path = SEGMENTDIR+f\"/{segemented_audio_name}\"\n",
    "            new_train_df.loc[new_train_df.shape[0]] = [\n",
    "                full_export_path,k[\"patient_id\"],k[\"Murmur\"],None\n",
    "            ]\n",
    "print(new_train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               filenames patient_id   Murmur  \\\n",
      "0      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "1      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "2      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "3      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "4      ./1.0.1/training_data_balanced/training_data/s...      14241  Present   \n",
      "...                                                  ...        ...      ...   \n",
      "49892  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49893  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49894  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49895  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "49896  ./1.0.1/training_data_balanced/training_data/s...      85349   Absent   \n",
      "\n",
      "       data  \n",
      "0      None  \n",
      "1      None  \n",
      "2      None  \n",
      "3      None  \n",
      "4      None  \n",
      "...     ...  \n",
      "49892  None  \n",
      "49893  None  \n",
      "49894  None  \n",
      "49895  None  \n",
      "49896  None  \n",
      "\n",
      "[49897 rows x 4 columns]\n",
      "./1.0.1/training_data_balanced/training_data/segmented_data/14241_AV_s0.wav\n"
     ]
    }
   ],
   "source": [
    "print(new_train_df)\n",
    "print(new_train_df[\"filenames\"][0])\n",
    "train_df = new_train_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6982/6982 [02:47<00:00, 41.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set class distribution (Post Signal Augment)\n",
      " Absent     42915\n",
      "Present    13964\n",
      "Name: Murmur, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# augmenting present class audio data\n",
    "filtered_train = train_df.loc[train_df[\"Murmur\"]!=\"Absent\"].copy()\n",
    "for i,k in tqdm(filtered_train.iterrows(),total=filtered_train.shape[0]):\n",
    "    S,sr = librosa.load(k[\"filenames\"],sr=4000)\n",
    "    augmented_signal = augment(S,sr)\n",
    "    augmented_signal_filename = k[\"filenames\"].replace(\".wav\",\"_a1.wav\")\n",
    "    augment_signal(S,sr,augmented_signal_filename)\n",
    "    train_df = train_df.append(pd.DataFrame(\n",
    "        data=[[augmented_signal_filename,k[\"patient_id\"],k[\"Murmur\"],np.array(None)]],\n",
    "        columns=list(train_df.columns.values)\n",
    "        ))\n",
    "print(\"\\nTraining set class distribution (Post Signal Augment)\\n\",train_df[\"Murmur\"].value_counts())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Murmur\"].value_counts()\n",
    "train_df[\"data\"] = np.array(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting features and augmenting present class mfcc spectogram\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6783/56879 [02:27<19:24, 43.01it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 21%|██▏       | 12124/56879 [04:06<15:10, 49.15it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 30%|███       | 17133/56879 [05:45<10:31, 62.90it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 31%|███       | 17532/56879 [05:51<09:39, 67.91it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 51%|█████     | 28918/56879 [09:17<07:17, 63.98it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 59%|█████▊    | 33285/56879 [10:44<06:21, 61.92it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 59%|█████▉    | 33510/56879 [10:48<05:38, 69.09it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 64%|██████▎   | 36216/56879 [11:41<05:36, 61.34it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 66%|██████▌   | 37265/56879 [12:01<07:03, 46.30it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 66%|██████▌   | 37442/56879 [12:04<05:24, 59.86it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      "/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 68%|██████▊   | 38556/56879 [12:25<05:03, 60.46it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 71%|███████▏  | 40544/56879 [13:06<05:07, 53.17it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 84%|████████▍ | 47898/56879 [15:25<02:26, 61.41it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 87%|████████▋ | 49428/56879 [15:53<02:09, 57.69it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 87%|████████▋ | 49491/56879 [15:54<02:00, 61.17it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      " 94%|█████████▍| 53405/56879 [17:29<01:07, 51.32it/s]/home/francis/fypj_phys/ubuntu_venv/lib/python3.8/site-packages/librosa/util/decorators.py:88: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  return f(*args, **kwargs)\n",
      "100%|██████████| 56879/56879 [19:00<00:00, 49.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set class distribution (Post Spectrogram augment))\n",
      " Absent     42915\n",
      "Present    20356\n",
      "Name: Murmur, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extracting features and augmenting mfcc spectogram for training set\n",
    "print(\"\\nExtracting features and augmenting present class mfcc spectogram\\n\")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "for i,k in tqdm(train_df.copy().iterrows(),total=train_df.copy().shape[0]):\n",
    "    S,sr = librosa.load(k[\"filenames\"],sr=4000)\n",
    "    if len(S) != 0:\n",
    "        scaled_mfccs , mfccs = mfccs_features_extract(S,sr)\n",
    "        train_df.loc[i,\"data\"] = scaled_mfccs\n",
    "        if k[\"Murmur\"] != \"Absent\":\n",
    "            mfccs_augment = augment_spec(mfccs)\n",
    "            mfccs_augment = np.mean(mfccs_augment.T,axis=0)\n",
    "            train_df = train_df.append(pd.DataFrame(\n",
    "                data=[[\n",
    "                    k[\"filenames\"].replace(\".wav\",\"_augmentspect.wav\"),\n",
    "                    k[\"patient_id\"],\n",
    "                    k[\"Murmur\"],\n",
    "                    mfccs_augment\n",
    "                ]],\n",
    "                columns=list(train_df.columns.values)\n",
    "            ))\n",
    "    else:\n",
    "        train_df.drop(index=i,axis=0)\n",
    "        continue\n",
    "print(\"\\nTraining set class distribution (Post Spectrogram augment))\\n\",train_df[\"Murmur\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trim absent class data to match size of present class data and shuffle \n",
      "Absent     20382\n",
      "Present    20356\n",
      "Name: Murmur, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class balancing for training set\n",
    "present_count = train_df[\"Murmur\"].value_counts()[1]\n",
    "print(\"Trim absent class data to match size of present class data and shuffle \")\n",
    "absent_ids = grab_id(present_count,train_df.loc[train_df[\"Murmur\"]==\"Absent\"][\"patient_id\"].value_counts())\n",
    "train_df = pd.concat([\n",
    "    train_df.loc[train_df[\"Murmur\"]==\"Present\"],\n",
    "    train_df.loc[(train_df[\"Murmur\"]==\"Absent\")&(train_df[\"patient_id\"].isin(absent_ids))]\n",
    "]).sample(frac=1)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "print(train_df[\"Murmur\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2267/529885081.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"data\"] = None\n",
      "100%|██████████| 604/604 [05:11<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing set class distribution (final)\n",
      " Absent     302\n",
      "Present    302\n",
      "Name: Murmur, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df[\"data\"] = None\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "for i,k in tqdm(test_df.copy().iterrows(),total=test_df.copy().shape[0]):\n",
    "    S,sr = librosa.load(data_path+k[\"filenames\"],sr=4000)\n",
    "    test_scaled_mfccs, test_melspect = mfccs_features_extract(S,sr)\n",
    "    test_df.loc[i,\"data\"] = test_scaled_mfccs\n",
    "test_df = test_df.sample(frac=1).reset_index()\n",
    "print(\"\\nTesting set class distribution (final)\\n\",test_df[\"Murmur\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2267/3690262261.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_train = np.array(train_df[\"data\"].tolist())\n"
     ]
    }
   ],
   "source": [
    "# manual splitting and assigning data to variables\n",
    "X_test = np.array(test_df[\"data\"].tolist())\n",
    "X_train = np.array(train_df[\"data\"].tolist())\n",
    "y_test = test_df[\"Murmur\"]\n",
    "y_train = train_df[\"Murmur\"]\n",
    "\n",
    "\n",
    "# export data \n",
    "import pickle \n",
    "\n",
    "pickle_out_X_train = open(\"./1.0.1/pickled_data/X_train_autosklearn_seg.pickle\",\"wb\")\n",
    "pickle.dump(X_train,pickle_out_X_train)\n",
    "pickle_out_X_train.close()\n",
    "\n",
    "pickle_out_X_test = open(\"./1.0.1/pickled_data/X_test_autosklearn_seg.pickle\",\"wb\")\n",
    "pickle.dump(X_test,pickle_out_X_test)\n",
    "pickle_out_X_test.close()\n",
    "\n",
    "\n",
    "pickle_out_y_train = open(\"./1.0.1/pickled_data/y_train_autosklearn_seg.pickle\",\"wb\")\n",
    "pickle.dump(y_train,pickle_out_y_train)\n",
    "pickle_out_y_train.close()\n",
    "\n",
    "pickle_out_y_test = open(\"./1.0.1/pickled_data/y_test_autosklearn_seg.pickle\",\"wb\")\n",
    "pickle.dump(y_test,pickle_out_y_test)\n",
    "pickle_out_y_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b43543f65750abaf68843f05bc2f17d6c89e154a5075b0a110863194543eb828"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ubuntu_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
